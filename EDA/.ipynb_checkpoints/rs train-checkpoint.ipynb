{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import Model\n",
    "import numpy as np\n",
    "from tensorflow.keras.initializers import TruncatedNormal\n",
    "from tqdm import tqdm\n",
    "from time import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# base_folder = 'F:\\\\Projects\\\\train\\\\episerver\\\\data\\\\rs\\\\'\n",
    "# base_folder = 'E:\\\\Projects\\\\Train\\\\episerver\\\\data\\\\rs\\\\'\n",
    "model_folder = 'E:\\\\Projects\\\\Train\\\\episerver\\\\model\\\\rs\\\\'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "if gpus.__len__() > 0:\n",
    "    tf.config.experimental.set_visible_devices(gpus[1], 'GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataSet:\n",
    "\n",
    "    def __init__(self, ratings, batch_size=128):\n",
    "        self.ratings = ratings\n",
    "        self.batch_size = batch_size\n",
    "        self.num_batch = self.ratings.shape[0] // self.batch_size\n",
    "\n",
    "    def shuffle(self):\n",
    "        np.random.shuffle(self.ratings)\n",
    "\n",
    "    def get_batch(self, i):\n",
    "        user_ids = self.ratings[i * self.batch_size: (i + 1) * self.batch_size, 0]\n",
    "        item_ids = self.ratings[i * self.batch_size: (i + 1) * self.batch_size, 1]\n",
    "        rates = self.ratings[i * self.batch_size: (i + 1) * self.batch_size, 2]\n",
    "        return (np.array(user_ids, dtype=np.int32),\n",
    "                np.array(item_ids, dtype=np.int32),\n",
    "                np.array(rates, dtype=np.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model without item_bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSModel(Model):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super(RSModel, self).__init__()\n",
    "        self.embedding_size = args['embedding_size']\n",
    "        self.keyword_embedding_size = args['keyword_embedding_size']\n",
    "        self.alpha = args['alpha']\n",
    "        self.beta = args['beta']\n",
    "        self.gamma = args['gamma']\n",
    "        self.num_items = args['num_items']\n",
    "        self.num_users = args['num_users']\n",
    "        self.num_keywords = args['num_keywords']\n",
    "        self.item_keywords = tf.constant(args['item_keywords'], dtype=tf.int32)\n",
    "        self.keyword_embedding = tf.keras.layers.Embedding(input_dim=self.num_keywords + 1, output_dim=self.keyword_embedding_size,\n",
    "                                                           embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                           mask_zero=True,\n",
    "                                                           embeddings_regularizer=tf.keras.regularizers.L2(self.alpha)\n",
    "                                                           )\n",
    "        self.user_embedding = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=self.embedding_size,\n",
    "                                                        embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                        embeddings_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.item_embedding = tf.keras.layers.Embedding(input_dim=self.num_items, output_dim=self.embedding_size,\n",
    "                                                        embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                        embeddings_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.bias_u = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=1,\n",
    "                                                embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                embeddings_regularizer=tf.keras.regularizers.L2(self.gamma))\n",
    "#         self.bias_i = tf.keras.layers.Embedding(input_dim=self.num_items, output_dim=1,\n",
    "#                                                 embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "#                                                 embeddings_regularizer=tf.keras.regularizers.L2(self.gamma))\n",
    "        self.mlp_dense = tf.keras.layers.Dense(units=1, activation='tanh')\n",
    "\n",
    "    def call(self, user_ids, item_ids):\n",
    "        user_bias = self.bias_u(user_ids)\n",
    "#         item_bias = self.bias_i(item_ids)\n",
    "        # matrix factorization\n",
    "        users_embedding = self.user_embedding(user_ids)\n",
    "        items_embedding = self.item_embedding(item_ids)\n",
    "        mf = tf.math.multiply(users_embedding, items_embedding)\n",
    "        # mlp\n",
    "        item_keyword = tf.nn.embedding_lookup(self.item_keywords, item_ids)\n",
    "        item_keyword_embedding = self.keyword_embedding(item_keyword)\n",
    "        item_encode = tf.reduce_sum(item_keyword_embedding, axis=1)\n",
    "        item_encode = self.mlp_dense(item_encode)\n",
    "        # rating score\n",
    "        r = tf.squeeze(user_bias) + tf.reduce_sum(mf, axis=1) + tf.reduce_sum(item_encode, axis=1)\n",
    "#         r = tf.squeeze(user_bias) + tf.squeeze(item_bias) + tf.reduce_sum(mf, axis=1) + tf.reduce_sum(item_encode, axis=1)\n",
    "        #         r = tf.squeeze(user_bias) + tf.squeeze(item_bias) + tf.reduce_sum(mf, axis=1)\n",
    "        return r\n",
    "\n",
    "    def loss_fn_rmse(self, predictions, labels):\n",
    "        #         rmse = tf.reduce_sum(tf.math.square(predictions - labels))\n",
    "        rmse = tf.sqrt(tf.reduce_sum(tf.math.square(predictions - labels)))\n",
    "        loss = rmse\n",
    "#         loss = rmse + tf.reduce_sum(self.keyword_embedding.losses)\n",
    "#         loss += tf.reduce_sum(self.user_embedding.losses) + tf.reduce_sum(self.item_embedding.losses)\n",
    "        #         loss += tf.reduce_sum(self.bias_u.losses) + tf.reduce_sum(self.bias_i.losses)\n",
    "        return loss, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model with attention\n",
    "    - self attention layer on keyword embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSModel_3(Model):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super(RSModel_3, self).__init__()\n",
    "        self.embedding_size = args['embedding_size']\n",
    "        self.keyword_embedding_size = args['keyword_embedding_size']\n",
    "        self.alpha = args['alpha']\n",
    "        self.beta = args['beta']\n",
    "        self.gamma = args['gamma']\n",
    "        self.num_items = args['num_items']\n",
    "        self.num_users = args['num_users']\n",
    "        self.num_keywords = args['num_keywords']\n",
    "        self.item_keywords = tf.constant(args['item_keywords'], dtype=tf.int32)\n",
    "        self.keyword_embedding = tf.keras.layers.Embedding(input_dim=self.num_keywords + 1, output_dim=self.keyword_embedding_size,\n",
    "                                                           embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                           mask_zero=True,\n",
    "                                                           embeddings_regularizer=tf.keras.regularizers.L2(self.alpha)\n",
    "                                                           )\n",
    "        self.user_embedding = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=self.embedding_size,\n",
    "                                                        embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                        embeddings_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "#         self.user_mlp_embedding = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=self.embedding_size,\n",
    "#                                                         embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "#                                                         embeddings_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.keyword_attention = tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=64, value_dim=64)\n",
    "        \n",
    "#         self.mlp_concatnate_layer = tf.keras.layers.Concatenate(axis=1)\n",
    "        self.item_embedding = tf.keras.layers.Embedding(input_dim=self.num_items, output_dim=self.embedding_size,\n",
    "                                                        embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                        embeddings_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.bias_u = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=1,\n",
    "                                                embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                embeddings_regularizer=tf.keras.regularizers.L2(self.gamma))\n",
    "        self.bias_i = tf.keras.layers.Embedding(input_dim=self.num_items, output_dim=1,\n",
    "                                                embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                embeddings_regularizer=tf.keras.regularizers.L2(self.gamma))\n",
    "        self.mlp_keyword_dense = tf.keras.layers.Dense(units=32, activation='sigmoid',\n",
    "                                                      kernel_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.mf_dense = tf.keras.layers.Dense(units=32, activation='sigmoid',\n",
    "                                                 kernel_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.concatnate_layer = tf.keras.layers.Concatenate(axis=1)\n",
    "        self.ouput_dense = tf.keras.layers.Dense(units=1, activation='relu',\n",
    "                                                 kernel_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "\n",
    "    def call(self, user_ids, item_ids):\n",
    "        user_bias = self.bias_u(user_ids)\n",
    "        item_bias = self.bias_i(item_ids)\n",
    "        # matrix factorization\n",
    "        users_embedding = self.user_embedding(user_ids)\n",
    "        items_embedding = self.item_embedding(item_ids)\n",
    "        mf = tf.math.multiply(users_embedding, items_embedding)\n",
    "        # mlp\n",
    "#         users_mlp_embedding = self.user_mlp_embedding(user_ids)\n",
    "        item_keyword = tf.nn.embedding_lookup(self.item_keywords, item_ids)\n",
    "        item_keyword_embedding = self.keyword_embedding(item_keyword)        \n",
    "        item_keyword_attention = self.keyword_attention(item_keyword_embedding, item_keyword_embedding, item_keyword_embedding)        \n",
    "        item_encode = tf.reduce_sum(item_keyword_attention, axis=1)    \n",
    "        \n",
    "        \n",
    "#         mlp_concatnate_output = self.mlp_concatnate_layer([users_mlp_embedding, item_encode])        \n",
    "#         item_encode = self.mlp_keyword_dense(item_encode)\n",
    "        mf_encode = self.mf_dense(item_encode)\n",
    "        \n",
    "        # concatnate mf and mlp\n",
    "        concatnate_output = self.concatnate_layer([mf_encode, item_encode])\n",
    "        output = self.ouput_dense(concatnate_output)\n",
    "        r = tf.squeeze(output) + tf.squeeze(user_bias) + tf.squeeze(item_bias)\n",
    "        \n",
    "        # rating score\n",
    "#         r = tf.squeeze(user_bias) + tf.reduce_sum(mf, axis=1) + tf.reduce_sum(item_encode, axis=1)\n",
    "#         r = tf.squeeze(user_bias) + tf.squeeze(item_bias) + tf.reduce_sum(mf, axis=1) + tf.reduce_sum(item_encode, axis=1)\n",
    "        #         r = tf.squeeze(user_bias) + tf.squeeze(item_bias) + tf.reduce_sum(mf, axis=1)\n",
    "        \n",
    "        return r\n",
    "\n",
    "    def loss_fn_rmse(self, predictions, labels):\n",
    "        rmse = tf.reduce_sum(tf.math.square(predictions - labels))\n",
    "#         rmse = tf.sqrt(tf.reduce_sum(tf.math.square(predictions - labels)))        \n",
    "        loss = rmse + tf.reduce_sum(self.keyword_embedding.losses)\n",
    "        loss += tf.reduce_sum(self.user_embedding.losses) + tf.reduce_sum(self.item_embedding.losses)\n",
    "        #         loss += tf.reduce_sum(self.bias_u.losses) + tf.reduce_sum(self.bias_i.losses)\n",
    "        loss += tf.reduce_sum(self.mlp_keyword_dense.losses) + tf.reduce_sum(self.mf_dense.losses)\n",
    "#         loss += tf.reduce_sum(self.user_mlp_embedding.losses)\n",
    "        loss += tf.reduce_sum(self.ouput_dense.losses)\n",
    "        return loss, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model notes\n",
    "    - model 4 is similar to model 3 but simpler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSModel_4(Model):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super(RSModel_4, self).__init__()\n",
    "        self.embedding_size = args['embedding_size']\n",
    "        self.keyword_embedding_size = args['keyword_embedding_size']\n",
    "        self.alpha = args['alpha']\n",
    "        self.beta = args['beta']\n",
    "        self.gamma = args['gamma']\n",
    "        self.num_items = args['num_items']\n",
    "        self.num_users = args['num_users']\n",
    "        self.num_keywords = args['num_keywords']\n",
    "        self.item_keywords = tf.constant(args['item_keywords'], dtype=tf.int32)\n",
    "        self.keyword_embedding = tf.keras.layers.Embedding(input_dim=self.num_keywords + 1, output_dim=self.keyword_embedding_size,\n",
    "                                                           embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                           mask_zero=True,\n",
    "                                                           embeddings_regularizer=tf.keras.regularizers.L2(self.alpha)\n",
    "                                                           )\n",
    "        self.user_embedding = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=self.embedding_size,\n",
    "                                                        embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                        embeddings_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "#         self.user_mlp_embedding = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=self.embedding_size,\n",
    "#                                                         embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "#                                                         embeddings_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.keyword_attention = tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=64, value_dim=64)\n",
    "        \n",
    "#         self.mlp_concatnate_layer = tf.keras.layers.Concatenate(axis=1)\n",
    "        self.item_embedding = tf.keras.layers.Embedding(input_dim=self.num_items, output_dim=self.embedding_size,\n",
    "                                                        embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                        embeddings_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.bias_u = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=1,\n",
    "                                                embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                embeddings_regularizer=tf.keras.regularizers.L2(self.gamma))\n",
    "#         self.bias_i = tf.keras.layers.Embedding(input_dim=self.num_items, output_dim=1,\n",
    "#                                                 embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "#                                                 embeddings_regularizer=tf.keras.regularizers.L2(self.gamma))\n",
    "        self.mlp_keyword_dense = tf.keras.layers.Dense(units=1, activation='sigmoid',\n",
    "                                                      kernel_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "#         self.mf_dense = tf.keras.layers.Dense(units=32, activation='sigmoid',\n",
    "#                                                  kernel_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.concatnate_layer = tf.keras.layers.Concatenate(axis=1)\n",
    "        self.ouput_dense = tf.keras.layers.Dense(units=1, activation='relu',\n",
    "                                                 kernel_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "\n",
    "    def call(self, user_ids, item_ids):\n",
    "        user_bias = self.bias_u(user_ids)\n",
    "#         item_bias = self.bias_i(item_ids)\n",
    "        # matrix factorization\n",
    "        users_embedding = self.user_embedding(user_ids)\n",
    "        items_embedding = self.item_embedding(item_ids)\n",
    "        mf = tf.math.multiply(users_embedding, items_embedding)\n",
    "        # mlp\n",
    "#         users_mlp_embedding = self.user_mlp_embedding(user_ids)\n",
    "        item_keyword = tf.nn.embedding_lookup(self.item_keywords, item_ids)\n",
    "        item_keyword_embedding = self.keyword_embedding(item_keyword)        \n",
    "        item_keyword_attention = self.keyword_attention(item_keyword_embedding, item_keyword_embedding, item_keyword_embedding)        \n",
    "        item_encode = tf.reduce_sum(item_keyword_attention, axis=1)    \n",
    "        \n",
    "        \n",
    "#         mlp_concatnate_output = self.mlp_concatnate_layer([users_mlp_embedding, item_encode])        \n",
    "        item_encode = self.mlp_keyword_dense(item_encode)\n",
    "#         mf_encode = self.mf_dense(item_encode)\n",
    "        \n",
    "        # concatnate mf and mlp\n",
    "#         concatnate_output = self.concatnate_layer([mf_encode, item_encode])\n",
    "#         output = self.ouput_dense(concatnate_output)\n",
    "#         r = tf.squeeze(output) + tf.squeeze(user_bias) + tf.squeeze(item_bias)\n",
    "        \n",
    "        # rating score\n",
    "        r = tf.squeeze(user_bias) + tf.reduce_sum(mf, axis=1) + tf.reduce_sum(item_encode, axis=1)\n",
    "#         r = tf.squeeze(user_bias) + tf.squeeze(item_bias) + tf.reduce_sum(mf, axis=1) + tf.reduce_sum(item_encode, axis=1)\n",
    "        #         r = tf.squeeze(user_bias) + tf.squeeze(item_bias) + tf.reduce_sum(mf, axis=1)\n",
    "        \n",
    "        return r\n",
    "\n",
    "    def loss_fn_rmse(self, predictions, labels):\n",
    "        rmse = tf.reduce_sum(tf.math.square(predictions - labels))\n",
    "#         rmse = tf.sqrt(tf.reduce_sum(tf.math.square(predictions - labels)))        \n",
    "        loss = rmse + tf.reduce_sum(self.keyword_embedding.losses)\n",
    "        loss += tf.reduce_sum(self.user_embedding.losses) + tf.reduce_sum(self.item_embedding.losses)\n",
    "        #         loss += tf.reduce_sum(self.bias_u.losses) + tf.reduce_sum(self.bias_i.losses)\n",
    "#         loss += tf.reduce_sum(self.mlp_keyword_dense.losses) + tf.reduce_sum(self.mf_dense.losses)\n",
    "        loss += tf.reduce_sum(self.mlp_keyword_dense.losses)\n",
    "#         loss += tf.reduce_sum(self.user_mlp_embedding.losses)\n",
    "        loss += tf.reduce_sum(self.ouput_dense.losses)\n",
    "        return loss, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NeuCF model\n",
    "    - try concatenate item_embedding and user_embedding pairwise product with item_keyword_embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### simple mf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSModel_5(Model):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super(RSModel_5, self).__init__()\n",
    "        self.embedding_size = args['embedding_size']\n",
    "        self.keyword_embedding_size = args['keyword_embedding_size']\n",
    "        self.alpha = args['alpha']\n",
    "        self.beta = args['beta']\n",
    "        self.gamma = args['gamma']\n",
    "        self.num_items = args['num_items']\n",
    "        self.num_users = args['num_users']\n",
    "        self.num_keywords = args['num_keywords']                \n",
    "        self.user_embedding = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=self.embedding_size,\n",
    "                                                        embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                        embeddings_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.item_embedding = tf.keras.layers.Embedding(input_dim=self.num_items, output_dim=self.embedding_size,\n",
    "                                                        embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                        embeddings_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.bias_u = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=1,\n",
    "                                                embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                embeddings_regularizer=tf.keras.regularizers.L2(self.gamma))\n",
    "        self.bias_i = tf.keras.layers.Embedding(input_dim=self.num_items, output_dim=1,\n",
    "                                                embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                embeddings_regularizer=tf.keras.regularizers.L2(self.gamma))        \n",
    "\n",
    "    def call(self, user_ids, item_ids):\n",
    "        user_bias = self.bias_u(user_ids)\n",
    "        item_bias = self.bias_i(item_ids)\n",
    "        # matrix factorization\n",
    "        users_embedding = self.user_embedding(user_ids)\n",
    "        items_embedding = self.item_embedding(item_ids)\n",
    "        mf = tf.math.multiply(users_embedding, items_embedding)\n",
    "        r = tf.squeeze(user_bias) + tf.squeeze(item_bias) + tf.reduce_sum(mf, axis=1)        \n",
    "        return r\n",
    "\n",
    "    def loss_fn_rmse(self, predictions, labels):\n",
    "        rmse = tf.reduce_sum(tf.math.square(predictions - labels))        \n",
    "        loss = rmse + tf.reduce_sum(self.user_embedding.losses) + tf.reduce_sum(self.item_embedding.losses)        \n",
    "        return loss, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### simple mf model with global mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSModel_6(Model):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super(RSModel_6, self).__init__()\n",
    "        self.embedding_size = args['embedding_size']\n",
    "        self.keyword_embedding_size = args['keyword_embedding_size']\n",
    "        self.mu = args['mu']\n",
    "        self.alpha = args['alpha']\n",
    "        self.beta = args['beta']\n",
    "        self.gamma = args['gamma']\n",
    "        self.num_items = args['num_items']\n",
    "        self.num_users = args['num_users']\n",
    "        self.num_keywords = args['num_keywords']\n",
    "        self.user_embedding = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=self.embedding_size,\n",
    "                                                        embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                        embeddings_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.item_embedding = tf.keras.layers.Embedding(input_dim=self.num_items, output_dim=self.embedding_size,\n",
    "                                                        embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                        embeddings_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.bias_u = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=1,\n",
    "                                                embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                embeddings_regularizer=tf.keras.regularizers.L2(self.gamma))\n",
    "        self.bias_i = tf.keras.layers.Embedding(input_dim=self.num_items, output_dim=1,\n",
    "                                                embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                embeddings_regularizer=tf.keras.regularizers.L2(self.gamma))        \n",
    "\n",
    "    def call(self, user_ids, item_ids):\n",
    "        user_bias = self.bias_u(user_ids)\n",
    "        item_bias = self.bias_i(item_ids)\n",
    "        # matrix factorization\n",
    "        users_embedding = self.user_embedding(user_ids)\n",
    "        items_embedding = self.item_embedding(item_ids)\n",
    "        mf = tf.math.multiply(users_embedding, items_embedding)\n",
    "        r = self.mu + tf.squeeze(user_bias) + tf.squeeze(item_bias) + tf.reduce_sum(mf, axis=1)        \n",
    "        return r\n",
    "\n",
    "    def loss_fn_rmse(self, predictions, labels):\n",
    "        rmse = tf.reduce_sum(tf.math.square(predictions - labels))        \n",
    "        loss = rmse + tf.reduce_sum(self.user_embedding.losses) + tf.reduce_sum(self.item_embedding.losses)        \n",
    "        return loss, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### keyword encode and global mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSModel_7(Model):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super(RSModel_7, self).__init__()\n",
    "        self.embedding_size = args['embedding_size']\n",
    "        self.keyword_embedding_size = args['keyword_embedding_size']\n",
    "        self.mu = args['mu']\n",
    "        self.alpha = args['alpha']\n",
    "        self.beta = args['beta']\n",
    "        self.gamma = args['gamma']\n",
    "        self.num_items = args['num_items']\n",
    "        self.num_users = args['num_users']\n",
    "        self.num_keywords = args['num_keywords']\n",
    "        self.item_keywords = tf.constant(args['item_keywords'], dtype=tf.int32)\n",
    "        self.keyword_embedding = tf.keras.layers.Embedding(input_dim=self.num_keywords + 1, output_dim=self.keyword_embedding_size,\n",
    "                                                           embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                           mask_zero=True,\n",
    "                                                           embeddings_regularizer=tf.keras.regularizers.L2(self.alpha)\n",
    "                                                           )\n",
    "        self.user_embedding = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=self.embedding_size,\n",
    "                                                        embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                        embeddings_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.item_embedding = tf.keras.layers.Embedding(input_dim=self.num_items, output_dim=self.embedding_size,\n",
    "                                                        embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                        embeddings_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.bias_u = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=1,\n",
    "                                                embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                embeddings_regularizer=tf.keras.regularizers.L2(self.gamma))\n",
    "        self.bias_i = tf.keras.layers.Embedding(input_dim=self.num_items, output_dim=1,\n",
    "                                                embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                embeddings_regularizer=tf.keras.regularizers.L2(self.gamma))\n",
    "        self.mlp_keyword_dense = tf.keras.layers.Dense(units=1)\n",
    "\n",
    "    def call(self, user_ids, item_ids):\n",
    "        user_bias = self.bias_u(user_ids)\n",
    "        item_bias = self.bias_i(item_ids)\n",
    "        # matrix factorization\n",
    "        users_embedding = self.user_embedding(user_ids)\n",
    "        items_embedding = self.item_embedding(item_ids)\n",
    "        mf = tf.math.multiply(users_embedding, items_embedding)\n",
    "        # mlp\n",
    "        item_keyword = tf.nn.embedding_lookup(self.item_keywords, item_ids)\n",
    "        item_keyword_embedding = self.keyword_embedding(item_keyword)\n",
    "        mask = self.keyword_embedding.compute_mask(item_keyword)\n",
    "        item_keyword_embedding = tf.multiply(item_keyword_embedding, tf.expand_dims(tf.cast(mask, tf.float32), 2))\n",
    "        item_encode = tf.reduce_sum(item_keyword_embedding, axis=1)\n",
    "        item_num_keywords = tf.reduce_sum(tf.cast(mask, tf.float32), axis=1) + 1e-8\n",
    "        item_encode = tf.math.divide(item_encode, tf.expand_dims(item_num_keywords, 1))\n",
    "        \n",
    "        item_encode = self.mlp_keyword_dense(item_encode)\n",
    "        item_encode = tf.reduce_sum(item_encode, axis=1)\n",
    "        \n",
    "#         item_bias = tf.clip_by_value(item_bias, clip_value_min=-1.5, clip_value_max=1.5)\n",
    "#         user_bias = tf.clip_by_value(user_bias, clip_value_min=-1.5, clip_value_max=1.5)\n",
    "#         item_encode = tf.clip_by_value(item_encode, clip_value_min=-1.5, clip_value_max=1.5)\n",
    "        # rating score\n",
    "        r = self.mu + tf.squeeze(user_bias) + tf.squeeze(item_bias) + tf.reduce_sum(mf, axis=1) + item_encode\n",
    "        return r\n",
    "\n",
    "    def loss_fn_rmse(self, predictions, labels):\n",
    "        rmse = tf.reduce_sum(tf.math.square(predictions - labels))\n",
    "        loss = rmse + tf.reduce_sum(self.keyword_embedding.losses)\n",
    "        loss += tf.reduce_sum(self.user_embedding.losses) + tf.reduce_sum(self.item_embedding.losses)\n",
    "        loss += tf.reduce_sum(self.mlp_keyword_dense.losses)\n",
    "        return loss, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### pairwise multiply user_embedding with item_keyword_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSModel_8(Model):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super(RSModel_8, self).__init__()\n",
    "        self.embedding_size = args['embedding_size']\n",
    "        self.keyword_embedding_size = args['keyword_embedding_size']\n",
    "        self.mu = args['mu']\n",
    "        self.alpha = args['alpha']\n",
    "        self.beta = args['beta']\n",
    "        self.gamma = args['gamma']\n",
    "        self.num_items = args['num_items']\n",
    "        self.num_users = args['num_users']\n",
    "        self.num_keywords = args['num_keywords']\n",
    "        self.item_keywords = tf.constant(args['item_keywords'], dtype=tf.int32)\n",
    "        self.keyword_embedding = tf.keras.layers.Embedding(input_dim=self.num_keywords + 1, output_dim=self.keyword_embedding_size,\n",
    "                                                           embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                           mask_zero=True,\n",
    "                                                           embeddings_regularizer=tf.keras.regularizers.L2(self.alpha)\n",
    "                                                           )\n",
    "        self.user_embedding = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=self.embedding_size,\n",
    "                                                        embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                        embeddings_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.item_embedding = tf.keras.layers.Embedding(input_dim=self.num_items, output_dim=self.embedding_size,\n",
    "                                                        embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                        embeddings_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.bias_u = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=1,\n",
    "                                                embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                embeddings_regularizer=tf.keras.regularizers.L2(self.gamma))\n",
    "        self.bias_i = tf.keras.layers.Embedding(input_dim=self.num_items, output_dim=1,\n",
    "                                                embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                embeddings_regularizer=tf.keras.regularizers.L2(self.gamma))\n",
    "#         self.mlp_keyword_dense = tf.keras.layers.Dense(units=1)\n",
    "\n",
    "    def call(self, user_ids, item_ids):\n",
    "        user_bias = self.bias_u(user_ids)\n",
    "        item_bias = self.bias_i(item_ids)\n",
    "        # matrix factorization\n",
    "        users_embedding = self.user_embedding(user_ids)\n",
    "        items_embedding = self.item_embedding(item_ids)\n",
    "        mf = tf.math.multiply(users_embedding, items_embedding)\n",
    "        # mlp\n",
    "        item_keyword = tf.nn.embedding_lookup(self.item_keywords, item_ids)\n",
    "        item_keyword_embedding = self.keyword_embedding(item_keyword)\n",
    "        mask = self.keyword_embedding.compute_mask(item_keyword)\n",
    "        item_keyword_embedding = tf.multiply(item_keyword_embedding, tf.expand_dims(tf.cast(mask, tf.float32), 2))\n",
    "        item_encode = tf.reduce_sum(item_keyword_embedding, axis=1)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#         item_encode = self.mlp_keyword_dense(item_encode)\n",
    "#         item_encode = tf.reduce_sum(item_encode, axis=1)\n",
    "        mf_keyword = tf.math.multiply(users_embedding, item_encode)\n",
    "        \n",
    "#         item_bias = tf.clip_by_value(item_bias, clip_value_min=-1.5, clip_value_max=1.5)\n",
    "#         user_bias = tf.clip_by_value(user_bias, clip_value_min=-1.5, clip_value_max=1.5)\n",
    "#         item_encode = tf.clip_by_value(item_encode, clip_value_min=-1.5, clip_value_max=1.5)\n",
    "        # rating score\n",
    "        r = self.mu + tf.squeeze(user_bias) + tf.squeeze(item_bias) + tf.reduce_sum(mf, axis=1) + tf.reduce_sum(mf_keyword, axis=1)\n",
    "        return r\n",
    "\n",
    "    def loss_fn_rmse(self, predictions, labels):\n",
    "        rmse = tf.reduce_sum(tf.math.square(predictions - labels))\n",
    "        loss = rmse + tf.reduce_sum(self.keyword_embedding.losses)\n",
    "        loss += tf.reduce_sum(self.user_embedding.losses) + tf.reduce_sum(self.item_embedding.losses)\n",
    "#         loss += tf.reduce_sum(self.mlp_keyword_dense.losses)\n",
    "        return loss, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### model with more hidden layers\n",
    "    - do not simply sum pairwise product from item_embedding and user_embedding\n",
    "    - user MLP to combine them, must user activation function (because without activation function --> no change in result)\n",
    "    - try concatenate item_embedding and user_embedding pairwise product with item_keyword_embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSModel_2(Model):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super(RSModel_2, self).__init__()\n",
    "        self.embedding_size = args['embedding_size']\n",
    "        self.keyword_embedding_size = args['keyword_embedding_size']\n",
    "        self.alpha = args['alpha']\n",
    "        self.beta = args['beta']\n",
    "        self.gamma = args['gamma']\n",
    "        self.num_items = args['num_items']\n",
    "        self.num_users = args['num_users']\n",
    "        self.num_keywords = args['num_keywords']\n",
    "        self.item_keywords = tf.constant(args['item_keywords'], dtype=tf.int32)\n",
    "        self.keyword_embedding = tf.keras.layers.Embedding(input_dim=self.num_keywords + 1, output_dim=self.keyword_embedding_size,\n",
    "                                                           embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                           mask_zero=True,\n",
    "                                                           embeddings_regularizer=tf.keras.regularizers.L2(self.alpha)\n",
    "                                                           )\n",
    "        self.user_embedding = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=self.embedding_size,\n",
    "                                                        embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                        embeddings_regularizer=tf.keras.regularizers.L2(self.beta))        \n",
    "        self.user_mlp_embedding = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=self.embedding_size,\n",
    "                                                        embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                        embeddings_regularizer=tf.keras.regularizers.L2(self.beta))        \n",
    "        self.mlp_concatnate_layer = tf.keras.layers.Concatenate(axis=1)\n",
    "        self.item_embedding = tf.keras.layers.Embedding(input_dim=self.num_items, output_dim=self.embedding_size,\n",
    "                                                        embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                        embeddings_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.bias_u = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=1,\n",
    "                                                embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                embeddings_regularizer=tf.keras.regularizers.L2(self.gamma))\n",
    "        self.bias_i = tf.keras.layers.Embedding(input_dim=self.num_items, output_dim=1,\n",
    "                                                embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                embeddings_regularizer=tf.keras.regularizers.L2(self.gamma))\n",
    "        self.mlp_keyword_dense = tf.keras.layers.Dense(units=32, activation='sigmoid',\n",
    "                                                      kernel_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.mf_dense = tf.keras.layers.Dense(units=32, activation='sigmoid',\n",
    "                                                 kernel_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.concatnate_layer = tf.keras.layers.Concatenate(axis=1)\n",
    "        self.ouput_dense = tf.keras.layers.Dense(units=1, activation='relu',\n",
    "                                                 kernel_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "\n",
    "    def call(self, user_ids, item_ids):\n",
    "        user_bias = self.bias_u(user_ids)\n",
    "        item_bias = self.bias_i(item_ids)\n",
    "        # matrix factorization\n",
    "        users_embedding = self.user_embedding(user_ids)\n",
    "        items_embedding = self.item_embedding(item_ids)\n",
    "        mf = tf.math.multiply(users_embedding, items_embedding)\n",
    "        # mlp\n",
    "        users_mlp_embedding = self.user_mlp_embedding(user_ids)\n",
    "        item_keyword = tf.nn.embedding_lookup(self.item_keywords, item_ids)\n",
    "        item_keyword_embedding = self.keyword_embedding(item_keyword)\n",
    "        item_encode = tf.reduce_sum(item_keyword_embedding, axis=1)\n",
    "        mlp_concatnate_output = self.mlp_concatnate_layer([users_mlp_embedding, item_encode])\n",
    "        \n",
    "        item_encode = self.mlp_keyword_dense(mlp_concatnate_output)\n",
    "        \n",
    "        mf_encode = self.mf_dense(item_encode)\n",
    "        \n",
    "        concatnate_output = self.concatnate_layer([mf_encode, item_encode])\n",
    "        output = self.ouput_dense(concatnate_output)\n",
    "        r = tf.squeeze(output) + tf.squeeze(user_bias) + tf.squeeze(item_bias)\n",
    "        \n",
    "        # rating score\n",
    "#         r = tf.squeeze(user_bias) + tf.reduce_sum(mf, axis=1) + tf.reduce_sum(item_encode, axis=1)\n",
    "#         r = tf.squeeze(user_bias) + tf.squeeze(item_bias) + tf.reduce_sum(mf, axis=1) + tf.reduce_sum(item_encode, axis=1)\n",
    "        #         r = tf.squeeze(user_bias) + tf.squeeze(item_bias) + tf.reduce_sum(mf, axis=1)\n",
    "        \n",
    "        return r\n",
    "\n",
    "    def loss_fn_rmse(self, predictions, labels):\n",
    "        rmse = tf.reduce_sum(tf.math.square(predictions - labels))\n",
    "#         rmse = tf.sqrt(tf.reduce_sum(tf.math.square(predictions - labels)))        \n",
    "        loss = rmse + tf.reduce_sum(self.keyword_embedding.losses)\n",
    "        loss += tf.reduce_sum(self.user_embedding.losses) + tf.reduce_sum(self.item_embedding.losses)\n",
    "        #         loss += tf.reduce_sum(self.bias_u.losses) + tf.reduce_sum(self.bias_i.losses)\n",
    "        loss += tf.reduce_sum(self.mlp_keyword_dense.losses) + tf.reduce_sum(self.mf_dense.losses)\n",
    "        loss += tf.reduce_sum(self.user_mlp_embedding.losses)\n",
    "        loss += tf.reduce_sum(self.ouput_dense.losses)\n",
    "        return loss, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RSModel_2_1(Model):\n",
    "\n",
    "    def __init__(self, args):\n",
    "        super(RSModel_2_1, self).__init__()\n",
    "        self.embedding_size = args['embedding_size']\n",
    "        self.keyword_embedding_size = args['keyword_embedding_size']\n",
    "        self.mu = args['mu']\n",
    "        self.alpha = args['alpha']\n",
    "        self.beta = args['beta']\n",
    "        self.gamma = args['gamma']\n",
    "        self.num_items = args['num_items']\n",
    "        self.num_users = args['num_users']\n",
    "        self.num_keywords = args['num_keywords']\n",
    "        self.item_keywords = tf.constant(args['item_keywords'], dtype=tf.int32)\n",
    "        self.keyword_embedding = tf.keras.layers.Embedding(input_dim=self.num_keywords + 1, output_dim=self.keyword_embedding_size,\n",
    "                                                           embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                           mask_zero=True,\n",
    "                                                           embeddings_regularizer=tf.keras.regularizers.L2(self.alpha)\n",
    "                                                           )\n",
    "        self.user_embedding = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=self.embedding_size,\n",
    "                                                        embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                        embeddings_regularizer=tf.keras.regularizers.L2(self.beta))        \n",
    "        self.user_mlp_embedding = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=self.embedding_size,\n",
    "                                                        embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                        embeddings_regularizer=tf.keras.regularizers.L2(self.beta))        \n",
    "        self.mlp_concatnate_layer = tf.keras.layers.Concatenate(axis=1)\n",
    "        self.item_embedding = tf.keras.layers.Embedding(input_dim=self.num_items, output_dim=self.embedding_size,\n",
    "                                                        embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                        embeddings_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.bias_u = tf.keras.layers.Embedding(input_dim=self.num_users + 1, output_dim=1,\n",
    "                                                embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                embeddings_regularizer=tf.keras.regularizers.L2(self.gamma))\n",
    "        self.bias_i = tf.keras.layers.Embedding(input_dim=self.num_items, output_dim=1,\n",
    "                                                embeddings_initializer=TruncatedNormal(mean=0., stddev=0.1),\n",
    "                                                embeddings_regularizer=tf.keras.regularizers.L2(self.gamma))\n",
    "        self.mlp_keyword_dense = tf.keras.layers.Dense(units=32, activation='sigmoid',\n",
    "                                                      kernel_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.mf_dense = tf.keras.layers.Dense(units=32, activation='sigmoid',\n",
    "                                                 kernel_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "        self.concatnate_layer = tf.keras.layers.Concatenate(axis=1)\n",
    "        self.ouput_dense = tf.keras.layers.Dense(units=1, activation='relu',\n",
    "                                                 kernel_regularizer=tf.keras.regularizers.L2(self.beta))\n",
    "\n",
    "    def call(self, user_ids, item_ids):\n",
    "        user_bias = self.bias_u(user_ids)\n",
    "        item_bias = self.bias_i(item_ids)\n",
    "        # matrix factorization\n",
    "        users_embedding = self.user_embedding(user_ids)\n",
    "        items_embedding = self.item_embedding(item_ids)\n",
    "        mf = tf.math.multiply(users_embedding, items_embedding)\n",
    "        # mlp\n",
    "        users_mlp_embedding = self.user_mlp_embedding(user_ids)\n",
    "        item_keyword = tf.nn.embedding_lookup(self.item_keywords, item_ids)\n",
    "        item_keyword_embedding = self.keyword_embedding(item_keyword)\n",
    "        \n",
    "        \n",
    "        \n",
    "        item_encode = tf.reduce_sum(item_keyword_embedding, axis=1)        \n",
    "        mlp_concatnate_output = self.mlp_concatnate_layer([users_mlp_embedding, item_encode])\n",
    "        \n",
    "        item_encode = self.mlp_keyword_dense(mlp_concatnate_output)\n",
    "        \n",
    "        mf_encode = self.mf_dense(item_encode)\n",
    "        \n",
    "        concatnate_output = self.concatnate_layer([mf_encode, item_encode])\n",
    "        output = self.ouput_dense(concatnate_output)\n",
    "        r = self.mu + tf.squeeze(output) + tf.squeeze(user_bias) + tf.squeeze(item_bias)            \n",
    "        return r\n",
    "\n",
    "    def loss_fn_rmse(self, predictions, labels):\n",
    "        rmse = tf.reduce_sum(tf.math.square(predictions - labels))\n",
    "        loss = rmse + tf.reduce_sum(self.keyword_embedding.losses)\n",
    "        loss += tf.reduce_sum(self.user_embedding.losses) + tf.reduce_sum(self.item_embedding.losses)        \n",
    "        loss += tf.reduce_sum(self.mlp_keyword_dense.losses) + tf.reduce_sum(self.mf_dense.losses)\n",
    "        loss += tf.reduce_sum(self.user_mlp_embedding.losses)\n",
    "        loss += tf.reduce_sum(self.ouput_dense.losses)\n",
    "        return loss, rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### training function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def train_step(rs_model, optimizer, user_ids, item_ids, ratings):\n",
    "    with tf.GradientTape() as tape:\n",
    "        predictions = rs_model(user_ids, item_ids)\n",
    "        loss, rmse = rs_model.loss_fn_rmse(predictions, ratings)\n",
    "    gradients = tape.gradient(target=loss, sources=rs_model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, rs_model.trainable_variables))\n",
    "    return loss, rmse\n",
    "\n",
    "\n",
    "def get_val_rmse(rs_model, val_dataset):\n",
    "    all_ratings = []\n",
    "    all_predictions = []\n",
    "    for i in tqdm(range(val_dataset.num_batch)):\n",
    "        user_ids, item_ids, ratings = val_dataset.get_batch(i)\n",
    "        predictions = rs_model(user_ids, item_ids)\n",
    "        all_predictions.append(predictions.numpy())\n",
    "        all_ratings.append(ratings)\n",
    "    val_predictions = np.concatenate(all_predictions, axis=0)\n",
    "    val_ratings = np.concatenate(all_ratings, axis=0)\n",
    "    return np.sqrt(np.mean((val_predictions - val_ratings) ** 2))\n",
    "\n",
    "\n",
    "def training(rs_model, optimizer, train_dataset, val_dataset, num_epochs, pretrained=False):\n",
    "    epoch_step = tf.Variable(0, dtype=tf.int32)\n",
    "    ckpt = tf.train.Checkpoint(rec_model=rs_model, epoch_step=epoch_step)\n",
    "    manager = tf.train.CheckpointManager(checkpoint=ckpt, directory=model_folder + 'rsmodel_ckpt', max_to_keep=3)\n",
    "    if pretrained:\n",
    "        ckpt.restore(manager.latest_checkpoint)\n",
    "    for epoch in range(num_epochs):\n",
    "        train_loss = tf.constant(0, tf.float32)\n",
    "        train_rmse = tf.constant(0, tf.float32)\n",
    "        start_load_data = time()\n",
    "        train_dataset.shuffle()\n",
    "        load_data_time = time() - start_load_data\n",
    "        start_train_time = time()\n",
    "        for i in tqdm(range(train_dataset.num_batch)):\n",
    "            user_ids, item_ids, ratings = train_dataset.get_batch(i)\n",
    "            loss_step, rmse_step = train_step(rs_model, optimizer, user_ids, item_ids, ratings)\n",
    "            train_loss += loss_step\n",
    "            train_rmse += rmse_step\n",
    "            if i > 1000:\n",
    "                break\n",
    "        train_time = time() - start_train_time\n",
    "        print('epoch: ', epoch, '. load data time: ', load_data_time, \n",
    "              '. train time: ', train_time, '. train loss: ', train_loss.numpy(),\n",
    "             '. train rmse: ', train_rmse.numpy()/(i * train_dataset.batch_size))\n",
    "        if epoch % 2 == 0:\n",
    "            val_rmse = get_val_rmse(rs_model, val_dataset)\n",
    "            score = {'val_rmse': val_rmse}\n",
    "\n",
    "            print('epoch: {}, score: {}'.format(epoch, score))\n",
    "            ckpt.epoch_step.assign_add(epoch + 1)\n",
    "#             pickle.dump(rs_model, open('./rsmodel_ckpt/' + rs_model + '_' + str(ckpt.epoch_step.numpy()) + '.pkl'))\n",
    "            manager.save()\n",
    "            # Save the weights\n",
    "#             rs_model.save_weights('./rsmodel_ckpt/my_checkpoint')\n",
    "#             rs_model.save('./saved_model/my_model')\n",
    "            \n",
    "            print('done save at epoch: ', ckpt.epoch_step.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pickle.load(open(model_folder + 'train.pkl', 'rb'))\n",
    "val = pickle.load(open(model_folder + 'val.pkl', 'rb'))\n",
    "test = pickle.load(open(model_folder + 'test.pkl', 'rb'))\n",
    "\n",
    "movie_id_idx_map = pickle.load(open(model_folder + 'movie_id_idx_map.pkl', 'rb'))\n",
    "idx_movie_id_map = pickle.load(open(model_folder + 'idx_movie_id_map.pkl', 'rb'))\n",
    "meta_data = pickle.load(open(model_folder + 'meta_data.pkl', 'rb'))\n",
    "\n",
    "item_keywords = pickle.load(open(model_folder + 'item_keywords.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = DataSet(train[['userId', 'itemId', 'rating']].values, batch_size=1024)\n",
    "val_dataset = DataSet(val[['userId', 'itemId', 'rating']].values, batch_size=1024)\n",
    "test_dataset = DataSet(test[['userId', 'itemId', 'rating']].values, batch_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3.528208498385696, 3.527078558945723, 3.5269755574597585)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['rating'].mean(), val['rating'].mean(), test['rating'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "args = dict()\n",
    "args['embedding_size'] = 64\n",
    "args['keyword_embedding_size'] = 64\n",
    "args['mu'] = train['rating'].mean()\n",
    "# args['mu'] = 0\n",
    "args['alpha'] = 0.005\n",
    "args['beta'] = 0.005\n",
    "args['gamma'] = 0.000\n",
    "args['num_items'] = meta_data['num_items']\n",
    "args['num_users'] = meta_data['num_users']\n",
    "args['num_keywords'] = meta_data['num_keywords']\n",
    "args['item_keywords'] = item_keywords\n",
    "\n",
    "\n",
    "# rsmodel = RSModel(args)\n",
    "# rsmodel = RSModel_2(args)\n",
    "# rsmodel = RSModel_2_1(args)\n",
    "# rsmodel = RSModel_3(args)\n",
    "# rsmodel = RSModel_4(args)\n",
    "# rsmodel = RSModel_5(args)\n",
    "# rsmodel = RSModel_6(args)\n",
    "rsmodel = RSModel_7(args)\n",
    "# rsmodel = RSModel_8(args)\n",
    "\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:42<59:20,  6.14it/s]\n",
      "  1%|                                                                              | 11/1270 [00:00<00:12, 102.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 . load data time:  43.02695369720459 . train time:  162.991197347641 . train loss:  1071020.6 . train rmse:  0.939278129097465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:08<00:00, 149.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, score: {'val_rmse': 0.9279637}\n",
      "done save at epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:43<59:34,  6.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 . load data time:  38.30358529090881 . train time:  163.6095449924469 . train loss:  1037285.56 . train rmse:  0.830105075588474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:29<54:15,  6.72it/s]\n",
      "  2%|                                                                             | 28/1270 [00:00<00:09, 133.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  2 . load data time:  43.65826725959778 . train time:  149.02054953575134 . train loss:  1008541.6 . train rmse:  0.791931213317932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:09<00:00, 131.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, score: {'val_rmse': 0.88833666}\n",
      "done save at epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:31<55:02,  6.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  3 . load data time:  41.744383811950684 . train time:  151.15584135055542 . train loss:  989163.75 . train rmse:  0.7756423873977585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:26<53:31,  6.81it/s]\n",
      "  2%|                                                                             | 21/1270 [00:00<00:06, 200.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  4 . load data time:  37.92958474159241 . train time:  146.98299884796143 . train loss:  978953.5 . train rmse:  0.7661305979177073\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:07<00:00, 160.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, score: {'val_rmse': 0.8796936}\n",
      "done save at epoch:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:29<54:17,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  5 . load data time:  37.96648573875427 . train time:  149.11330389976501 . train loss:  972594.75 . train rmse:  0.7607346267014236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:33<55:56,  6.52it/s]\n",
      "  1%|                                                                              | 14/1270 [00:00<00:09, 138.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  6 . load data time:  38.9049756526947 . train time:  153.64219403266907 . train loss:  966004.06 . train rmse:  0.7557167563881431\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:09<00:00, 130.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, score: {'val_rmse': 0.8756067}\n",
      "done save at epoch:  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:35<56:43,  6.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  7 . load data time:  41.461142778396606 . train time:  155.77149987220764 . train loss:  965331.1 . train rmse:  0.7540670998922953\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:31<55:04,  6.62it/s]\n",
      "  3%|                                                                             | 34/1270 [00:00<00:08, 149.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  8 . load data time:  39.81753706932068 . train time:  151.25757312774658 . train loss:  961787.7 . train rmse:  0.7498556741110453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:07<00:00, 166.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, score: {'val_rmse': 0.8731478}\n",
      "done save at epoch:  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:34<56:21,  6.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  9 . load data time:  38.11708211898804 . train time:  154.77217268943787 . train loss:  956775.06 . train rmse:  0.7447006118881119\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training(rsmodel, opt, train_dataset, val_dataset, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:29<54:18,  6.71it/s]\n",
      "  1%|                                                                              | 15/1270 [00:00<00:09, 136.73it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 . load data time:  37.38204765319824 . train time:  149.135244846344 . train loss:  1069000.9 . train rmse:  0.9359018666879995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:08<00:00, 146.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, score: {'val_rmse': 0.9281823}\n",
      "done save at epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:31<55:16,  6.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 . load data time:  38.78330039978027 . train time:  151.8100929260254 . train loss:  1037888.1 . train rmse:  0.829054002637987\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:28<54:13,  6.72it/s]\n",
      "  1%|                                                                              | 18/1270 [00:00<00:07, 173.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  2 . load data time:  39.76068878173828 . train time:  148.89289212226868 . train loss:  1016158.9 . train rmse:  0.7966453102561502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:08<00:00, 158.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, score: {'val_rmse': 0.8894604}\n",
      "done save at epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|                                                                             | 161/22872 [00:24<58:00,  6.52it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-14d1c3b6ba28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrsmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-3bde97a45e29>\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(rs_model, optimizer, train_dataset, val_dataset, num_epochs, pretrained)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mload_data_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_load_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mstart_train_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0muser_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mloss_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmse_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrs_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlock_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlock_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                         \u001b[1;31m# If no `miniters` was specified, adjust automatically\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36mrefresh\u001b[1;34m(self, nolock, lock_args)\u001b[0m\n\u001b[0;32m   1378\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1380\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1381\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnolock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36mdisplay\u001b[1;34m(self, msg, pos)\u001b[0m\n\u001b[0;32m   1512\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmsg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36mprint_status\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mprint_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[0mlen_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisp_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m             \u001b[0mfp_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\r'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_len\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m             \u001b[0mlast_len\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36mfp_write\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfp_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m             \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m             \u001b[0mfp_flush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[0mlast_len\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tqdm\\utils.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mIOError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mflush\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    350\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m                 \u001b[1;31m# and give a timeout to avoid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m                 \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mevt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflush_timeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    353\u001b[0m                     \u001b[1;31m# write directly to __stderr__ instead of warning because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m                     \u001b[1;31m# if this is happening sys.stderr may be the problem.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 558\u001b[1;33m                 \u001b[0msignaled\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    559\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\threading.py\u001b[0m in \u001b[0;36mwait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    304\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    305\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 306\u001b[1;33m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    307\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    308\u001b[0m                     \u001b[0mgotit\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mwaiter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training(rsmodel, opt, train_dataset, val_dataset, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:26<53:16,  6.84it/s]\n",
      "  3%|                                                                            | 42/1270 [00:00<00:06, 202.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 . load data time:  39.373722076416016 . train time:  146.295836687088 . train loss:  1172094.1 . train rmse:  0.9622701517232767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:05<00:00, 229.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, score: {'val_rmse': 0.9522887}\n",
      "done save at epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:26<53:28,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 . load data time:  37.85977101325989 . train time:  146.84636521339417 . train loss:  1240810.4 . train rmse:  0.8821183089371566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:27<53:37,  6.80it/s]\n",
      "  4%|                                                                           | 51/1270 [00:00<00:04, 244.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  2 . load data time:  38.21083164215088 . train time:  147.25028491020203 . train loss:  1234509.2 . train rmse:  0.8495979118537712\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:05<00:00, 220.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, score: {'val_rmse': 0.92180395}\n",
      "done save at epoch:  4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-19-14d1c3b6ba28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrsmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-14-3bde97a45e29>\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(rs_model, optimizer, train_dataset, val_dataset, num_epochs, pretrained)\u001b[0m\n\u001b[0;32m     32\u001b[0m         \u001b[0mtrain_rmse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstant\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m         \u001b[0mstart_load_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 34\u001b[1;33m         \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m         \u001b[0mload_data_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_load_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mstart_train_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-4-1638cf38bac5>\u001b[0m in \u001b[0;36mshuffle\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mratings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training(rsmodel, opt, train_dataset, val_dataset, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "       nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rsmodel.keyword_embedding.weights[0].numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = np.array([0, 1, 2], dtype=np.int32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_ouput = rsmodel.keyword_embedding(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3, 64), dtype=float32, numpy=\n",
       "array([[nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan],\n",
       "       [nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan,\n",
       "        nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan, nan]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = rsmodel.keyword_embedding.compute_mask(inputs)\n",
    "tf.multiply(embedding_ouput, tf.expand_dims(tf.cast(mask, tf.float32), 1)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=bool, numpy=array([False,  True,  True])>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3, 64])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_ouput.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(3,), dtype=float32, numpy=array([0., 1., 1.], dtype=float32)>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([3])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=2.0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.reduce_sum(tf.cast(mask, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:28<53:55,  6.76it/s]\n",
      "  2%|                                                                             | 21/1270 [00:00<00:06, 206.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 . load data time:  41.693519830703735 . train time:  148.07308554649353 . train loss:  1113414.1 . train rmse:  0.9786702555257243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:05<00:00, 213.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, score: {'val_rmse': 0.9340567}\n",
      "done save at epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:25<52:52,  6.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 . load data time:  38.76335430145264 . train time:  145.1927855014801 . train loss:  1049989.5 . train rmse:  0.8396779002247752\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:30<54:51,  6.64it/s]\n",
      "  2%|                                                                             | 21/1270 [00:00<00:06, 204.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  2 . load data time:  39.29692769050598 . train time:  150.65518164634705 . train loss:  1023757.2 . train rmse:  0.8022185943938873\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:06<00:00, 203.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, score: {'val_rmse': 0.8953211}\n",
      "done save at epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:29<54:20,  6.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  3 . load data time:  38.81920647621155 . train time:  149.22799634933472 . train loss:  1005128.56 . train rmse:  0.7858314780922203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:31<55:12,  6.60it/s]\n",
      "  2%|                                                                             | 21/1270 [00:00<00:06, 204.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  4 . load data time:  38.68456530570984 . train time:  151.60962891578674 . train loss:  993472.8 . train rmse:  0.776420113090035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:05<00:00, 212.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, score: {'val_rmse': 0.8842201}\n",
      "done save at epoch:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:30<54:48,  6.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  5 . load data time:  40.455830335617065 . train time:  150.5305140018463 . train loss:  984538.5 . train rmse:  0.7690794922850587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:32<55:34,  6.56it/s]\n",
      "  1%|                                                                              | 15/1270 [00:00<00:09, 135.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  6 . load data time:  40.45283842086792 . train time:  152.61095094680786 . train loss:  976946.9 . train rmse:  0.7625834858500874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:07<00:00, 175.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, score: {'val_rmse': 0.88025796}\n",
      "done save at epoch:  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:38<57:48,  6.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  7 . load data time:  42.01964807510376 . train time:  158.73457860946655 . train loss:  978202.5 . train rmse:  0.7631292657537775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:31<55:06,  6.61it/s]\n",
      "  1%|                                                                             | 19/1270 [00:00<00:06, 186.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  8 . load data time:  39.49340319633484 . train time:  151.3473289012909 . train loss:  967230.25 . train rmse:  0.753494247451767\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:06<00:00, 196.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, score: {'val_rmse': 0.87651366}\n",
      "done save at epoch:  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|                                                                            | 519/22872 [01:20<57:29,  6.48it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-14d1c3b6ba28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrsmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-3bde97a45e29>\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(rs_model, optimizer, train_dataset, val_dataset, num_epochs, pretrained)\u001b[0m\n\u001b[0;32m     35\u001b[0m         \u001b[0mload_data_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_load_data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     36\u001b[0m         \u001b[0mstart_train_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 37\u001b[1;33m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     38\u001b[0m             \u001b[0muser_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m             \u001b[0mloss_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmse_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrs_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36m__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1182\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1183\u001b[0m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1184\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlock_args\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlock_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1185\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1186\u001b[0m                         \u001b[1;31m# If no `miniters` was specified, adjust automatically\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36mrefresh\u001b[1;34m(self, nolock, lock_args)\u001b[0m\n\u001b[0;32m   1378\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1379\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1380\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1381\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnolock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1382\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36mdisplay\u001b[1;34m(self, msg, pos)\u001b[0m\n\u001b[0;32m   1512\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1513\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1514\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mmsg\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmsg\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1515\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpos\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1516\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmoveto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mpos\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36mprint_status\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    333\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mprint_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m             \u001b[0mlen_s\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdisp_len\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m             \u001b[0mfp_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'\\r'\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0ms\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m' '\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlast_len\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    336\u001b[0m             \u001b[0mlast_len\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen_s\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tqdm\\std.py\u001b[0m in \u001b[0;36mfp_write\u001b[1;34m(s)\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    327\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mfp_write\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 328\u001b[1;33m             \u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_unicode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ms\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    329\u001b[0m             \u001b[0mfp_flush\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    330\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tqdm\\utils.py\u001b[0m in \u001b[0;36minner\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    221\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0minner\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    222\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 223\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    224\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mIOError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOSError\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    225\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrno\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mwrite\u001b[1;34m(self, string)\u001b[0m\n\u001b[0;32m    402\u001b[0m             \u001b[0mis_child\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_master_process\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[1;31m# only touch the buffer in the IO thread to avoid races\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 404\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpub_thread\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mschedule\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mlambda\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_buffer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    405\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mis_child\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m                 \u001b[1;31m# mp.Pool cannot be trusted to flush promptly (or ever),\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\ipykernel\\iostream.py\u001b[0m in \u001b[0;36mschedule\u001b[1;34m(self, f)\u001b[0m\n\u001b[0;32m    203\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_events\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m             \u001b[1;31m# wake event thread (message content is ignored)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_event_pipe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb''\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\zmq\\sugar\\socket.py\u001b[0m in \u001b[0;36msend\u001b[1;34m(self, data, flags, copy, track, routing_id, group)\u001b[0m\n\u001b[0;32m    414\u001b[0m                                  copy_threshold=self.copy_threshold)\n\u001b[0;32m    415\u001b[0m             \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgroup\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 416\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mSocket\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mflags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrack\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    417\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msend_multipart\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmsg_parts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrack\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mzmq\\backend\\cython\\socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq\\backend\\cython\\socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket.Socket.send\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mzmq\\backend\\cython\\socket.pyx\u001b[0m in \u001b[0;36mzmq.backend.cython.socket._send_copy\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\zmq\\backend\\cython\\checkrc.pxd\u001b[0m in \u001b[0;36mzmq.backend.cython.checkrc._check_rc\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training(rsmodel, opt, train_dataset, val_dataset, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:31<55:02,  6.62it/s]\n",
      "  2%|                                                                             | 22/1270 [00:00<00:05, 216.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 . load data time:  40.50669240951538 . train time:  151.14985918998718 . train loss:  998072.4 . train rmse:  0.9655678793862388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:06<00:00, 203.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, score: {'val_rmse': 0.948061}\n",
      "done save at epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:26<53:25,  6.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 . load data time:  40.31320929527283 . train time:  146.69078159332275 . train loss:  903565.9 . train rmse:  0.8553388140180133\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:28<53:57,  6.76it/s]\n",
      "  1%|                                                                              | 18/1270 [00:00<00:07, 178.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  2 . load data time:  38.71548271179199 . train time:  148.17880272865295 . train loss:  882468.1 . train rmse:  0.8206265780118319\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:06<00:00, 205.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, score: {'val_rmse': 0.920457}\n",
      "done save at epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:26<53:14,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  3 . load data time:  38.08018088340759 . train time:  146.22702074050903 . train loss:  870715.4 . train rmse:  0.7993069552517794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|                                                                           | 772/22872 [01:52<53:45,  6.85it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-14d1c3b6ba28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrsmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-12-3bde97a45e29>\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(rs_model, optimizer, train_dataset, val_dataset, num_epochs, pretrained)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0muser_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mloss_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmse_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrs_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mtrain_rmse\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mrmse_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training(rsmodel, opt, train_dataset, val_dataset, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:32<55:39,  6.55it/s]\n",
      "  5%|                                                                           | 62/1270 [00:00<00:01, 615.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 . load data time:  44.306533098220825 . train time:  152.83277320861816 . train loss:  992115.44 . train rmse:  0.9600127045805756\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:01<00:00, 643.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, score: {'val_rmse': 0.9403755}\n",
      "done save at epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:26<53:12,  6.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 . load data time:  39.44353890419006 . train time:  146.09537267684937 . train loss:  900376.56 . train rmse:  0.8526588157935814\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:24<52:34,  6.93it/s]\n",
      "  5%|                                                                           | 66/1270 [00:00<00:01, 655.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  2 . load data time:  40.697184801101685 . train time:  144.356023311615 . train loss:  879067.56 . train rmse:  0.817979627794081\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:01<00:00, 658.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, score: {'val_rmse': 0.9179143}\n",
      "done save at epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:24<52:40,  6.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  3 . load data time:  39.20417666435242 . train time:  144.65223050117493 . train loss:  865448.9 . train rmse:  0.7951005903276411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:22<51:58,  7.01it/s]\n",
      "  5%|                                                                          | 69/1270 [00:00<00:01, 685.00it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  4 . load data time:  41.41626191139221 . train time:  142.70842814445496 . train loss:  854127.2 . train rmse:  0.777066378445773\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:01<00:00, 673.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, score: {'val_rmse': 0.9096095}\n",
      "done save at epoch:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                          | 942/22872 [02:13<51:40,  7.07it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-20-14d1c3b6ba28>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtraining\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrsmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mopt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_dataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-11-3bde97a45e29>\u001b[0m in \u001b[0;36mtraining\u001b[1;34m(rs_model, optimizer, train_dataset, val_dataset, num_epochs, pretrained)\u001b[0m\n\u001b[0;32m     37\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m             \u001b[0muser_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratings\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_dataset\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 39\u001b[1;33m             \u001b[0mloss_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrmse_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_step\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrs_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muser_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mitem_ids\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mratings\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     40\u001b[0m             \u001b[0mtrain_loss\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mloss_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m             \u001b[0mtrain_rmse\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mrmse_step\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    827\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 828\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xla\"\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[1;32melse\u001b[0m \u001b[1;34m\"nonXla\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    853\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    854\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 855\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    856\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    857\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m-> 2942\u001b[1;33m     return graph_function._call_flat(\n\u001b[0m\u001b[0;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0;32m   2944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[0;32m   1917\u001b[0m       \u001b[1;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1918\u001b[1;33m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[0;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    553\u001b[0m       \u001b[1;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    554\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 555\u001b[1;33m           outputs = execute.execute(\n\u001b[0m\u001b[0;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     57\u001b[0m   \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[0;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[0;32m     61\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training(rsmodel, opt, train_dataset, val_dataset, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using surprise library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import SVD, NMF\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "\n",
    "# Load the movielens-100k dataset (download it if needed).\n",
    "data = Dataset.load_builtin('ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating RMSE, MAE of algorithm NMF on 5 split(s).\n",
      "\n",
      "                  Fold 1  Fold 2  Fold 3  Fold 4  Fold 5  Mean    Std     \n",
      "RMSE (testset)    0.9973  0.9892  0.9883  0.9849  0.9866  0.9893  0.0043  \n",
      "MAE (testset)     0.7651  0.7625  0.7587  0.7546  0.7553  0.7592  0.0041  \n",
      "Fit time          9.12    9.12    9.06    9.09    9.35    9.15    0.10    \n",
      "Test time         0.14    0.29    0.13    0.14    0.14    0.17    0.06    \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'test_rmse': array([0.9972816 , 0.98924323, 0.98830935, 0.98491456, 0.98662294]),\n",
       " 'test_mae': array([0.76506188, 0.76250315, 0.7587079 , 0.75456071, 0.75530337]),\n",
       " 'fit_time': (9.116624116897583,\n",
       "  9.116622924804688,\n",
       "  9.064760684967041,\n",
       "  9.094681024551392,\n",
       "  9.351994514465332),\n",
       " 'test_time': (0.13862919807434082,\n",
       "  0.2872333526611328,\n",
       "  0.13464045524597168,\n",
       "  0.13563776016235352,\n",
       "  0.1406247615814209)}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Use the famous SVD algorithm.\n",
    "# algo = SVD()\n",
    "algo = NMF(n_factors=32)\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the famous SVD algorithm.\n",
    "# algo = SVD()\n",
    "algo = NMF(n_factors=32)\n",
    "\n",
    "# Run 5-fold cross-validation and print results.\n",
    "cross_validate(algo, data, measures=['RMSE', 'MAE'], cv=5, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_embedding = rsmodel.item_embedding.weights[0].numpy()\n",
    "user_embedding = rsmodel.user_embedding.weights[0].numpy()\n",
    "keyword_embedding = rsmodel.keyword_embedding.weights[0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\seaborn\\distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
      "  warnings.warn(msg, FutureWarning)\n",
      "c:\\users\\admin\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\seaborn\\distributions.py:305: UserWarning: Dataset has 0 variance; skipping density estimate.\n",
      "  warnings.warn(msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22874e62bb0>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(item_embedding[:,7][:10000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_i = np.squeeze(rsmodel.bias_i.weights[0].numpy())\n",
    "bias_u = np.squeeze(rsmodel.bias_u.weights[0].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x22874ba9550>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(bias_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x22874d8b790>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.displot(bias_u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:29<54:35,  6.68it/s]\n",
      "  3%|                                                                            | 40/1270 [00:00<00:03, 393.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 . load data time:  34.365124464035034 . train time:  149.92917370796204 . train loss:  1120230.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:03<00:00, 401.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, score: {'val_rmse': 0.93591845}\n",
      "done save at epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:28<54:10,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 . load data time:  34.087865352630615 . train time:  148.75131464004517 . train loss:  1044392.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:27<53:41,  6.79it/s]\n",
      "  3%|                                                                            | 40/1270 [00:00<00:03, 389.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  2 . load data time:  32.71967267990112 . train time:  147.4328145980835 . train loss:  1021546.25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:03<00:00, 409.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, score: {'val_rmse': 0.89548504}\n",
      "done save at epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:25<53:03,  6.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  3 . load data time:  33.15340971946716 . train time:  145.6895010471344 . train loss:  1000892.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:24<52:37,  6.93it/s]\n",
      "  3%|                                                                            | 39/1270 [00:00<00:03, 383.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  4 . load data time:  32.7544584274292 . train time:  144.4976589679718 . train loss:  988913.4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:03<00:00, 410.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, score: {'val_rmse': 0.8833952}\n",
      "done save at epoch:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:32<55:34,  6.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  5 . load data time:  32.53402066230774 . train time:  152.60102224349976 . train loss:  984102.9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:33<55:44,  6.54it/s]\n",
      "  6%|                                                                          | 77/1270 [00:00<00:03, 375.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  6 . load data time:  34.2314817905426 . train time:  153.05780148506165 . train loss:  977282.94\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:03<00:00, 386.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 6, score: {'val_rmse': 0.87926906}\n",
      "done save at epoch:  16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:27<53:39,  6.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  7 . load data time:  34.48778676986694 . train time:  147.34806656837463 . train loss:  973930.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:26<53:26,  6.82it/s]\n",
      "  6%|                                                                          | 74/1270 [00:00<00:03, 354.98it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  8 . load data time:  32.73548197746277 . train time:  146.7486686706543 . train loss:  972354.3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:03<00:00, 387.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 8, score: {'val_rmse': 0.8769898}\n",
      "done save at epoch:  25\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:29<54:18,  6.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  9 . load data time:  32.93003034591675 . train time:  149.15323948860168 . train loss:  965386.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training(rsmodel, opt, train_dataset, val_dataset, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:25<53:05,  6.86it/s]\n",
      "  8%|                                                                       | 100/1270 [00:00<00:01, 983.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  0 . load data time:  34.43304133415222 . train time:  145.82096195220947 . train loss:  6085918.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:01<00:00, 985.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, score: {'val_rmse': 1.3326454}\n",
      "done save at epoch:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:24<52:37,  6.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  1 . load data time:  33.41731905937195 . train time:  144.53356170654297 . train loss:  2219069.8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:25<52:59,  6.88it/s]\n",
      "  7%|                                                                         | 93/1270 [00:00<00:01, 923.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  2 . load data time:  33.36878800392151 . train time:  145.50499296188354 . train loss:  1835103.2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:01<00:00, 959.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 2, score: {'val_rmse': 1.0594991}\n",
      "done save at epoch:  4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:28<54:09,  6.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  3 . load data time:  33.23911452293396 . train time:  148.71837329864502 . train loss:  1558471.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|                                                                         | 1001/22872 [02:24<52:41,  6.92it/s]\n",
      " 15%|                                                                  | 195/1270 [00:00<00:01, 963.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch:  4 . load data time:  32.914036989212036 . train time:  144.70812463760376 . train loss:  1347344.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|| 1270/1270 [00:01<00:00, 973.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 4, score: {'val_rmse': 0.9718058}\n",
      "done save at epoch:  9\n"
     ]
    }
   ],
   "source": [
    "training(rsmodel, opt, train_dataset, val_dataset, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
